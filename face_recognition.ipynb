{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4ca631-ff28-4b15-a2d0-ec2dbc996922",
   "metadata": {},
   "source": [
    "# Sistema de Detecção e Reconhecimento de Faces com TensorFlow\n",
    "\n",
    "**Ambiente utilizado:** Linux Ubuntu 24.04, Python 3.11\n",
    "\n",
    "**Framework Principal:** TensorFlow\n",
    "\n",
    "**Componentes:**\n",
    "1.  **Detector de Faces:** Rede pré-treinada `MTCNN` (Multi-task Cascaded Convolutional Networks).\n",
    "2.  **Classificador (Reconhecimento) de Faces:** Rede pré-treinada `FaceNet` para gerar *embeddings* (vetores de características) e um classificador baseado em distância para identificar a pessoa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20f743-1289-4a19-b978-7af6e8d093a7",
   "metadata": {},
   "source": [
    "## 1. Setup do Ambiente\n",
    "\n",
    "A célula abaixo contém os comandos de instalação necessários para executar este notebook. Se você já configurou seu ambiente virtual conforme o `README.md`, pode pular esta etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593108b4-572a-456d-9960-70d44871d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comandos para instalação via pip (execute no terminal dentro do seu ambiente virtual)\n",
    "# !pip install tensorflow jupyterlab mtcnn keras-facenet opencv-python matplotlib scikit-learn\n",
    "\n",
    "print(\"Ambiente pronto para execução.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f6ab98-81c5-4745-b98c-92d834545048",
   "metadata": {},
   "source": [
    "## 2. Configurações Globais\n",
    "\n",
    "Centralizar as configurações aqui facilita a alteração de parâmetros sem precisar modificar o restante do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d0549-2d10-43ab-b84b-0ef68f1aeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PARÂMETROS CONFIGURÁVEIS ---\n",
    "\n",
    "# Diretório onde as imagens das pessoas conhecidas estão armazenadas\n",
    "DATABASE_DIR = 'database'\n",
    "\n",
    "# Caminho para a imagem de teste que será analisada\n",
    "TEST_IMAGE_PATH = 'test_images/imagem_de_teste.jpg'\n",
    "\n",
    "# Limiar de confiança para o reconhecimento. \n",
    "# Um valor menor torna o sistema mais rigoroso. Valores típicos ficam entre 0.4 e 0.7.\n",
    "RECOGNITION_THRESHOLD = 0.5\n",
    "\n",
    "# Tamanho da entrada da rede FaceNet\n",
    "FACENET_INPUT_SIZE = (160, 160)\n",
    "\n",
    "print(\"Configurações definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb8c7b-2fc9-4c61-9245-aadae70da03e",
   "metadata": {},
   "source": [
    "## 3. Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb33895-9a5f-4428-81c6-8c36ba132e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras_facenet import FaceNet\n",
    "from matplotlib import pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Silenciar logs excessivos do TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5513a2-1e5a-4451-b74b-261c984feef0",
   "metadata": {},
   "source": [
    "## 4. Inicialização dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e4d37-ed63-4093-9540-ab28622ab468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar os modelos pré-treinados\n",
    "print(\"Carregando modelos... Isso pode levar alguns segundos.\")\n",
    "\n",
    "# Detector de Faces (MTCNN)\n",
    "detector = MTCNN()\n",
    "\n",
    "# Extrator de Embeddings (FaceNet)\n",
    "embedder = FaceNet()\n",
    "\n",
    "print(\"Detector (MTCNN) e Extrator de Embeddings (FaceNet) carregados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040898d-0d6e-4cb1-8d98-c9b3b686e098",
   "metadata": {},
   "source": [
    "## 5. Construção do Banco de Dados de Faces\n",
    "\n",
    "Nesta etapa, vamos processar as imagens do diretório `database`. Para cada rosto encontrado, extraímos seu ***embedding*** (uma representação vetorial de 512 dimensões, que funciona como uma \"impressão digital\" matemática) e o armazenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7d255-430c-46b3-a648-2506119b5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face_database(directory):\n",
    "    \"\"\"\n",
    "    Carrega imagens de um diretório, detecta faces, extrai embeddings\n",
    "    e armazena junto com os nomes das pessoas.\n",
    "    \"\"\"\n",
    "    database = {'embeddings': [], 'names': []}\n",
    "    \n",
    "    for person_name in os.listdir(directory):\n",
    "        person_dir = os.path.join(directory, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processando: {person_name}...\")\n",
    "        for filename in os.listdir(person_dir):\n",
    "            path = os.path.join(person_dir, filename)\n",
    "            \n",
    "            image = cv2.imread(path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"  Aviso: Não foi possível carregar a imagem {path}. Pulando.\")\n",
    "                continue\n",
    "            \n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = detector.detect_faces(image_rgb)\n",
    "            \n",
    "            if results:\n",
    "                best_result = max(results, key=lambda r: r['confidence'])\n",
    "                x1, y1, width, height = best_result['box']\n",
    "                x1, y1 = abs(x1), abs(y1)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                \n",
    "                face = image_rgb[y1:y2, x1:x2]\n",
    "                \n",
    "\n",
    "                face_resized = cv2.resize(face, FACENET_INPUT_SIZE)\n",
    "                face_array = np.asarray(face_resized)\n",
    "                face_expanded = np.expand_dims(face_array, axis=0)\n",
    "                \n",
    "                embedding = embedder.embeddings(face_expanded)\n",
    "                \n",
    "                database['embeddings'].append(embedding[0])\n",
    "                database['names'].append(person_name)\n",
    "\n",
    "    database['embeddings'] = np.asarray(database['embeddings'])\n",
    "    return database\n",
    "\n",
    "# Carregar nosso banco de dados usando a variável de configuração\n",
    "known_faces_db = load_face_database(DATABASE_DIR)\n",
    "\n",
    "# Codificar os nomes para facilitar a manipulação\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(known_faces_db['names'])\n",
    "\n",
    "print(\"\\nBanco de dados de faces carregado com sucesso.\")\n",
    "print(f\"Total de amostras de faces: {len(known_faces_db['names'])}\")\n",
    "print(f\"Pessoas únicas no banco de dados: {len(np.unique(known_faces_db['names']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ae2a1-e1dd-427e-910d-8ec47a6adfbf",
   "metadata": {},
   "source": [
    "## 6. Função Principal de Detecção e Reconhecimento\n",
    "\n",
    "Esta função recebe uma nova imagem e realiza o processo de reconhecimento. Para cada rosto detectado, ela calcula seu *embedding* e o compara com os do banco de dados usando a **distância cosseno**. Se a distância for menor que o `RECOGNITION_THRESHOLD`, consideramos que a pessoa foi reconhecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a59db8-e326-4b2c-8535-a90036f8548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(image_path, db, threshold):\n",
    "    \"\"\"\n",
    "    Lê uma imagem, detecta todas as faces e tenta reconhecê-las\n",
    "    comparando com o banco de dados.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Erro: Não foi possível carregar a imagem de teste em {image_path}\")\n",
    "        return None\n",
    "        \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    detections = detector.detect_faces(image_rgb)\n",
    "    \n",
    "    if not detections:\n",
    "        print(\"Nenhuma face detectada na imagem de teste.\")\n",
    "        return image\n",
    "    \n",
    "    print(f\"Detectadas {len(detections)} faces.\")\n",
    "    \n",
    "    for face_info in detections:\n",
    "        x1, y1, width, height = face_info['box']\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        \n",
    "        face = image_rgb[y1:y2, x1:x2]\n",
    "        if face.size == 0: continue\n",
    "            \n",
    "        face_resized = cv2.resize(face, FACENET_INPUT_SIZE)\n",
    "        face_array = np.asarray(face_resized)\n",
    "        face_expanded = np.expand_dims(face_array, axis=0)\n",
    "        \n",
    "        new_embedding = embedder.embeddings(face_expanded)[0]\n",
    "        \n",
    "        distances = pairwise_distances([new_embedding], db['embeddings'], metric='cosine')[0]\n",
    "        \n",
    "        min_dist_idx = np.argmin(distances)\n",
    "        min_dist_val = distances[min_dist_idx]\n",
    "        \n",
    "        # Reconhecido\n",
    "        if min_dist_val < threshold:\n",
    "            person_name = le.inverse_transform([labels[min_dist_idx]])[0]\n",
    "            # Remove o prefixo do nome da pasta para exibição\n",
    "            display_name = person_name.replace('_', ' ').title()\n",
    "            label = f\"{display_name} ({min_dist_val:.2f})\"\n",
    "            color = (0, 255, 0) # Verde\n",
    "        # Não reconhecido\n",
    "        else:\n",
    "            label = f\"Desconhecido ({min_dist_val:.2f})\"\n",
    "            color = (0, 0, 255) # Vermelho\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885b29e-e37c-4346-a626-fc28fc0fad8e",
   "metadata": {},
   "source": [
    "## 7. Execução e Visualização do Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb61d3-a2c4-456c-9ae5-d494c558fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o reconhecimento usando as variáveis de configuração\n",
    "result_image = recognize_faces(TEST_IMAGE_PATH, known_faces_db, threshold=RECOGNITION_THRESHOLD)\n",
    "\n",
    "# Exibir o resultado usando Matplotlib\n",
    "if result_image is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Resultado do Reconhecimento Facial\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529e239-8fca-4232-9483-171cffc23cf8",
   "metadata": {},
   "source": [
    "## 8. (Bônus) Reconhecimento em Tempo Real com Webcam\n",
    "\n",
    "A célula abaixo ativa a webcam e aplica o mesmo processo de reconhecimento em tempo real. Pressione a tecla 'q' para fechar a janela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9ce3d-69a5-4dff-9bfd-18ad029676ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def run_realtime_recognition(db, threshold):\n",
    "    \"\"\"Ativa a webcam e executa o reconhecimento facial em tempo real.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Erro: Não foi possível abrir a webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # A lógica de reconhecimento é a mesma da função anterior, aplicada ao frame da webcam\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = detector.detect_faces(frame_rgb)\n",
    "        \n",
    "        for face_info in detections:\n",
    "            x1, y1, width, height = face_info['box']\n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            \n",
    "            face = frame_rgb[y1:y2, x1:x2]\n",
    "            if face.size == 0: continue\n",
    "            \n",
    "            face_resized = cv2.resize(face, FACENET_INPUT_SIZE)\n",
    "            face_array = np.asarray(face_resized)\n",
    "            face_expanded = np.expand_dims(face_array, axis=0)\n",
    "            \n",
    "            new_embedding = embedder.embeddings(face_expanded)[0]\n",
    "            \n",
    "            distances = pairwise_distances([new_embedding], db['embeddings'], metric='cosine')[0]\n",
    "            min_dist_idx = np.argmin(distances)\n",
    "            min_dist_val = distances[min_dist_idx]\n",
    "            \n",
    "            if min_dist_val < threshold:\n",
    "                person_name = le.inverse_transform([labels[min_dist_idx]])[0]\n",
    "                display_name = person_name.replace('_', ' ').title()\n",
    "                label = f\"{display_name}\"\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                label = \"Desconhecido\"\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "        cv2.imshow('Reconhecimento Facial - Pressione \"q\" para sair', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Para executar o modo webcam, descomente a linha abaixo:\n",
    "# run_realtime_recognition(known_faces_db, threshold=RECOGNITION_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b7e4e-4f0b-4c4b-a7a1-2626d8dbe8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
